{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21-03-29 자연어처리 04_RNN (c)cherryuki (ji)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ch04. RNN(순환 신경망)\n",
    "## 1. 문맥을 이용하여 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\n",
    "그의 말이 법이다\n",
    "가는 말이 고와야 오는 말이 곱다\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5, 6, 1, 7, 8, 1, 9, 10, 1, 11]\n",
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "encoded = t.texts_to_sequences([text])[0]\n",
    "print(encoded)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['있다'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 4, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['경마장에 있는 말이 뛰고 있다'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 문장: 경마장에 있는 말이 뛰고 있다\n",
      "encoded 문장: [2, 3, 1, 4, 5]\n",
      "원래 문장: 그의 말이 법이다\n",
      "encoded 문장: [6, 1, 7]\n",
      "원래 문장: 가는 말이 고와야 오는 말이 곱다\n",
      "encoded 문장: [8, 1, 9, 10, 1, 11]\n",
      "원래 문장: \n",
      "encoded 문장: []\n",
      "\n",
      "[ 2:경마장에 3:있는 ]\n",
      "[ 2:경마장에 3:있는 1:말이 ]\n",
      "[ 2:경마장에 3:있는 1:말이 4:뛰고 ]\n",
      "[ 2:경마장에 3:있는 1:말이 4:뛰고 5:있다 ]\n",
      "[ 3:있는 1:말이 ]\n",
      "[ 3:있는 1:말이 4:뛰고 ]\n",
      "[ 3:있는 1:말이 4:뛰고 5:있다 ]\n",
      "[ 1:말이 4:뛰고 ]\n",
      "[ 1:말이 4:뛰고 5:있다 ]\n",
      "[ 4:뛰고 5:있다 ]\n",
      "[ 6:그의 1:말이 ]\n",
      "[ 6:그의 1:말이 7:법이다 ]\n",
      "[ 1:말이 7:법이다 ]\n",
      "[ 8:가는 1:말이 ]\n",
      "[ 8:가는 1:말이 9:고와야 ]\n",
      "[ 8:가는 1:말이 9:고와야 10:오는 ]\n",
      "[ 8:가는 1:말이 9:고와야 10:오는 1:말이 ]\n",
      "[ 8:가는 1:말이 9:고와야 10:오는 1:말이 11:곱다 ]\n",
      "[ 1:말이 9:고와야 ]\n",
      "[ 1:말이 9:고와야 10:오는 ]\n",
      "[ 1:말이 9:고와야 10:오는 1:말이 ]\n",
      "[ 1:말이 9:고와야 10:오는 1:말이 11:곱다 ]\n",
      "[ 9:고와야 10:오는 ]\n",
      "[ 9:고와야 10:오는 1:말이 ]\n",
      "[ 9:고와야 10:오는 1:말이 11:곱다 ]\n",
      "[ 10:오는 1:말이 ]\n",
      "[ 10:오는 1:말이 11:곱다 ]\n",
      "[ 1:말이 11:곱다 ]\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    print('원래 문장:', line)\n",
    "    print('encoded 문장:', encoded)\n",
    "    for i in range(0, len(encoded)-1):\n",
    "        for j in range(i+2, len(encoded)+1):\n",
    "            sequences.append(encoded[i:j])\n",
    "#제대로 encode되었는지 확인\n",
    "print()\n",
    "for sequence in sequences:\n",
    "    print('[', end=' ')\n",
    "    for word_seq in sequence:\n",
    "        for key, value in t.word_index.items():\n",
    "            if value==word_seq:\n",
    "                print(\"{}:{}\".format(value, key), end=' ')\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 2, 3, 4, 2, 3, 2, 2, 3, 2, 2, 3, 4, 5, 6, 2, 3, 4, 5, 2, 3, 4, 2, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print([len(s) for s in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequences에 가장 많은 단어가 들어 있는 개수\n",
    "maxlen = max([len(s) for s in sequences])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences), len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequences를 훈련가능한 데이터로 만들기\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences=sequences, maxlen=maxlen,\n",
    "                         padding='pre') #앞에 0을 붙임\n",
    "type(sequences), len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  3,  1],\n",
       "       [ 0,  0,  0,  3,  1,  4],\n",
       "       [ 0,  0,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  1,  4],\n",
       "       [ 0,  0,  0,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11],\n",
       "       [ 0,  0,  0,  0,  1,  9],\n",
       "       [ 0,  0,  0,  1,  9, 10],\n",
       "       [ 0,  0,  1,  9, 10,  1],\n",
       "       [ 0,  1,  9, 10,  1, 11],\n",
       "       [ 0,  0,  0,  0,  9, 10],\n",
       "       [ 0,  0,  0,  9, 10,  1],\n",
       "       [ 0,  0,  9, 10,  1, 11],\n",
       "       [ 0,  0,  0,  0, 10,  1],\n",
       "       [ 0,  0,  0, 10,  1, 11],\n",
       "       [ 0,  0,  0,  0,  1, 11]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  5,  1,  4,  5,  4,  5,  5,  1,  7,  7,  1,  9, 10,  1,\n",
       "       11,  9, 10,  1, 11, 10,  1, 11,  1, 11, 11])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#독립변수(X)와 종속변수(Y) 분리\n",
    "X = sequences[:, :-1]\n",
    "Y = sequences[:, -1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len(t.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#종속변수(Y)를 원핫 인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(Y, num_classes = vocab_size)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 5), (28, 12), 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 - 0s - loss: 2.4877 - accuracy: 0.0357\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4759 - accuracy: 0.0714\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4641 - accuracy: 0.1786\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4524 - accuracy: 0.1786\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4406 - accuracy: 0.1429\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.4286 - accuracy: 0.1429\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.4164 - accuracy: 0.1071\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.4039 - accuracy: 0.1429\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3910 - accuracy: 0.1429\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3776 - accuracy: 0.1786\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3637 - accuracy: 0.2143\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.3492 - accuracy: 0.2143\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.3340 - accuracy: 0.2857\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.3181 - accuracy: 0.2857\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.3016 - accuracy: 0.2857\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2843 - accuracy: 0.3214\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.2664 - accuracy: 0.3214\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.2478 - accuracy: 0.3214\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.2286 - accuracy: 0.3214\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.2090 - accuracy: 0.2857\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.1890 - accuracy: 0.2857\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.1689 - accuracy: 0.2857\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.1487 - accuracy: 0.2857\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.1286 - accuracy: 0.2857\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.1089 - accuracy: 0.2857\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 2.0897 - accuracy: 0.2857\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 2.0711 - accuracy: 0.2857\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 2.0532 - accuracy: 0.2857\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 2.0362 - accuracy: 0.2857\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 2.0200 - accuracy: 0.2857\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 2.0047 - accuracy: 0.2857\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.9904 - accuracy: 0.2857\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.9768 - accuracy: 0.2857\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.9640 - accuracy: 0.2857\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.9520 - accuracy: 0.2857\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.9406 - accuracy: 0.2857\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.9298 - accuracy: 0.2857\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.9194 - accuracy: 0.2857\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.9095 - accuracy: 0.3214\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.8998 - accuracy: 0.3214\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.8904 - accuracy: 0.3214\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.8812 - accuracy: 0.3214\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.8721 - accuracy: 0.3571\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.8629 - accuracy: 0.3571\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.8538 - accuracy: 0.3571\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.8446 - accuracy: 0.3571\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.8353 - accuracy: 0.3571\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.8260 - accuracy: 0.3571\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.8165 - accuracy: 0.3571\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.8070 - accuracy: 0.3929\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.7973 - accuracy: 0.3929\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.7876 - accuracy: 0.3929\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.7777 - accuracy: 0.3929\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.7677 - accuracy: 0.3929\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.7576 - accuracy: 0.4286\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.7473 - accuracy: 0.4286\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.7369 - accuracy: 0.4286\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.7262 - accuracy: 0.4286\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.7153 - accuracy: 0.4286\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.7041 - accuracy: 0.4286\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.6926 - accuracy: 0.4286\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.6808 - accuracy: 0.4643\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.6687 - accuracy: 0.4643\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.6563 - accuracy: 0.4643\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.6437 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.6307 - accuracy: 0.5357\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.6175 - accuracy: 0.5357\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.6041 - accuracy: 0.5357\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.5905 - accuracy: 0.5357\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.5766 - accuracy: 0.5357\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.5627 - accuracy: 0.5357\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.5486 - accuracy: 0.5714\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.5343 - accuracy: 0.5714\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.5200 - accuracy: 0.5714\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.5056 - accuracy: 0.5714\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.4911 - accuracy: 0.5714\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.4766 - accuracy: 0.5714\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.4620 - accuracy: 0.6071\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.4474 - accuracy: 0.6071\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.4328 - accuracy: 0.6429\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 1.4181 - accuracy: 0.6429\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 1.4035 - accuracy: 0.6429\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 1.3888 - accuracy: 0.6429\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 1.3742 - accuracy: 0.6429\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 1.3595 - accuracy: 0.6429\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 1.3449 - accuracy: 0.6429\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 1.3303 - accuracy: 0.6429\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 1.3157 - accuracy: 0.6786\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 1.3012 - accuracy: 0.6786\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 1.2867 - accuracy: 0.6786\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 1.2723 - accuracy: 0.6786\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 1.2580 - accuracy: 0.6786\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 1.2438 - accuracy: 0.6786\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 1.2298 - accuracy: 0.6786\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 1.2159 - accuracy: 0.6786\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 1.2021 - accuracy: 0.6786\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 1.1885 - accuracy: 0.6786\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 1.1751 - accuracy: 0.6786\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 1.1619 - accuracy: 0.6786\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 1.1489 - accuracy: 0.6786\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 1.1361 - accuracy: 0.6786\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 1.1235 - accuracy: 0.6786\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 1.1111 - accuracy: 0.6786\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 1.0988 - accuracy: 0.6786\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 1.0868 - accuracy: 0.6786\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 1.0751 - accuracy: 0.6786\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 1.0635 - accuracy: 0.6786\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 1.0521 - accuracy: 0.6786\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 1.0409 - accuracy: 0.6786\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 1.0299 - accuracy: 0.6786\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 1.0192 - accuracy: 0.6786\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 1.0086 - accuracy: 0.6786\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.9982 - accuracy: 0.6786\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.9880 - accuracy: 0.6786\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.9780 - accuracy: 0.6786\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.9682 - accuracy: 0.6786\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.9585 - accuracy: 0.6786\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.9491 - accuracy: 0.6786\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.9397 - accuracy: 0.6786\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.9306 - accuracy: 0.6786\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.9216 - accuracy: 0.6786\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.9128 - accuracy: 0.6786\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.9041 - accuracy: 0.6786\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.8955 - accuracy: 0.6786\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.8872 - accuracy: 0.6786\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.8789 - accuracy: 0.6786\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.8708 - accuracy: 0.6786\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.8628 - accuracy: 0.6786\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.8550 - accuracy: 0.6786\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.8472 - accuracy: 0.6786\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.8396 - accuracy: 0.6786\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.8321 - accuracy: 0.6786\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.8247 - accuracy: 0.6786\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.8175 - accuracy: 0.6786\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.8103 - accuracy: 0.6786\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.8033 - accuracy: 0.6786\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.7963 - accuracy: 0.7143\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.7895 - accuracy: 0.7143\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.7827 - accuracy: 0.7143\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.7761 - accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.7695 - accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.7630 - accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.7567 - accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.7504 - accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.7441 - accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.7380 - accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.7319 - accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.7260 - accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.7201 - accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.7142 - accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.7085 - accuracy: 0.7857\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.7028 - accuracy: 0.7857\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.6972 - accuracy: 0.8214\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.6916 - accuracy: 0.8214\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.6861 - accuracy: 0.8214\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.6807 - accuracy: 0.8214\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.6753 - accuracy: 0.8214\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.6700 - accuracy: 0.8214\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.6648 - accuracy: 0.8214\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.6596 - accuracy: 0.8214\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.6545 - accuracy: 0.8214\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.6494 - accuracy: 0.8214\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.6444 - accuracy: 0.8214\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.6394 - accuracy: 0.8214\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.6345 - accuracy: 0.8214\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.6297 - accuracy: 0.8214\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.6249 - accuracy: 0.8214\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.6201 - accuracy: 0.8571\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.6154 - accuracy: 0.8571\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.6108 - accuracy: 0.8571\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.6062 - accuracy: 0.8571\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.6016 - accuracy: 0.8571\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.5971 - accuracy: 0.8571\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.5927 - accuracy: 0.8571\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.5882 - accuracy: 0.8571\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.5839 - accuracy: 0.8571\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.5795 - accuracy: 0.8571\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.5753 - accuracy: 0.8571\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.5710 - accuracy: 0.8571\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.5668 - accuracy: 0.8571\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.5627 - accuracy: 0.8571\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.5586 - accuracy: 0.8571\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.5545 - accuracy: 0.8571\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.5504 - accuracy: 0.8571\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.5465 - accuracy: 0.8571\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.5425 - accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.5386 - accuracy: 0.8571\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.5347 - accuracy: 0.8571\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.5309 - accuracy: 0.8571\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.5271 - accuracy: 0.8571\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.5233 - accuracy: 0.8571\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.5196 - accuracy: 0.8571\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.5123 - accuracy: 0.8571\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.5086 - accuracy: 0.8571\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.5051 - accuracy: 0.8571\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.5015 - accuracy: 0.8571\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.4980 - accuracy: 0.8571\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.4945 - accuracy: 0.8571\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.4911 - accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n",
    "\n",
    "#RNN 모델 생성\n",
    "model = Sequential()\n",
    "#희소행렬로 변환(10:벡터)\n",
    "model.add(Embedding(vocab_size, 10, input_length=X.shape[1]))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "#모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#모델 학습 시키기\n",
    "hist = model.fit(X, Y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48767781257629395, 0.8571428656578064]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 평가\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20bab12a250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습과정 보기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'], color='r', label='loss')\n",
    "plt.plot(hist.history['accuracy'], color='g', label='accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: 1\n",
      "예측 단어: 말이\n"
     ]
    }
   ],
   "source": [
    "#'경마장에' 뒤에 나오는 단어를 model에 의해 추측\n",
    "encoded = t.texts_to_sequences(['경마장에'])[0]\n",
    "encoded = pad_sequences([encoded], maxlen=maxlen-1, padding='pre')\n",
    "result = model.predict_classes(encoded)\n",
    "print('예측 결과:', result[0])\n",
    "for key, value in t.word_index.items():\n",
    "    if result[0]==value:\n",
    "        print('예측 단어:', key)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력단어: 가는 말이\n",
      "예측 결과: 9\n",
      "예측 단어: 고와야\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#사용자에게 입력받은 단어 다음 말 추측하기\n",
    "word = input('입력단어: ')\n",
    "encoded = t.texts_to_sequences([word])[0]\n",
    "encoded = pad_sequences([encoded], maxlen=maxlen-1, padding='pre')\n",
    "result = np.argmax(model.predict(encoded))\n",
    "print('예측 결과:', result)\n",
    "for key, value in t.word_index.items():\n",
    "    if result==value:\n",
    "        print('예측 단어:', key)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다음 문맥 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'가는' 이후에 올 단어 5개 예측 => 가는 말이 고와야 오는 말이 곱다\n",
    "# ----                 ---\n",
    "def sentence_generation(model, t, current_word, n):\n",
    "    init_word = current_word\n",
    "    print(\"입력 단어 :\", init_word)\n",
    "    for i in range(1,n+1):\n",
    "        encoded = t.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=maxlen-1, padding='pre')\n",
    "        result = np.argmax(model.predict(encoded))\n",
    "        for word, index in t.word_index.items():\n",
    "            if index==result:\n",
    "                print(\"{}번째 : {}:{}\".format(i, word, result))\n",
    "                current_word = current_word + ' ' + word\n",
    "                break;\n",
    "    return current_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 : 경마장에 있는\n",
      "1번째 : 말이:1\n",
      "2번째 : 뛰고:4\n",
      "3번째 : 있다:5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'경마장에 있는 말이 뛰고 있다'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '경마장에 있는', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 단어 : 가는\n",
      "1번째 : 말이:1\n",
      "2번째 : 고와야:9\n",
      "3번째 : 오는:10\n",
      "4번째 : 말이:1\n",
      "5번째 : 곱다:11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, '가는', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1/1 - 0s - loss: 2.4848 - accuracy: 0.0714\n",
      "Epoch 2/250\n",
      "1/1 - 0s - loss: 2.4821 - accuracy: 0.1786\n",
      "Epoch 3/250\n",
      "1/1 - 0s - loss: 2.4793 - accuracy: 0.2857\n",
      "Epoch 4/250\n",
      "1/1 - 0s - loss: 2.4766 - accuracy: 0.2857\n",
      "Epoch 5/250\n",
      "1/1 - 0s - loss: 2.4738 - accuracy: 0.2857\n",
      "Epoch 6/250\n",
      "1/1 - 0s - loss: 2.4710 - accuracy: 0.2857\n",
      "Epoch 7/250\n",
      "1/1 - 0s - loss: 2.4682 - accuracy: 0.2857\n",
      "Epoch 8/250\n",
      "1/1 - 0s - loss: 2.4653 - accuracy: 0.2857\n",
      "Epoch 9/250\n",
      "1/1 - 0s - loss: 2.4623 - accuracy: 0.2857\n",
      "Epoch 10/250\n",
      "1/1 - 0s - loss: 2.4592 - accuracy: 0.2857\n",
      "Epoch 11/250\n",
      "1/1 - 0s - loss: 2.4560 - accuracy: 0.2857\n",
      "Epoch 12/250\n",
      "1/1 - 0s - loss: 2.4527 - accuracy: 0.2857\n",
      "Epoch 13/250\n",
      "1/1 - 0s - loss: 2.4493 - accuracy: 0.2857\n",
      "Epoch 14/250\n",
      "1/1 - 0s - loss: 2.4457 - accuracy: 0.2857\n",
      "Epoch 15/250\n",
      "1/1 - 0s - loss: 2.4420 - accuracy: 0.2857\n",
      "Epoch 16/250\n",
      "1/1 - 0s - loss: 2.4381 - accuracy: 0.2857\n",
      "Epoch 17/250\n",
      "1/1 - 0s - loss: 2.4340 - accuracy: 0.2857\n",
      "Epoch 18/250\n",
      "1/1 - 0s - loss: 2.4297 - accuracy: 0.2857\n",
      "Epoch 19/250\n",
      "1/1 - 0s - loss: 2.4252 - accuracy: 0.2857\n",
      "Epoch 20/250\n",
      "1/1 - 0s - loss: 2.4205 - accuracy: 0.2857\n",
      "Epoch 21/250\n",
      "1/1 - 0s - loss: 2.4155 - accuracy: 0.2857\n",
      "Epoch 22/250\n",
      "1/1 - 0s - loss: 2.4103 - accuracy: 0.2857\n",
      "Epoch 23/250\n",
      "1/1 - 0s - loss: 2.4047 - accuracy: 0.2857\n",
      "Epoch 24/250\n",
      "1/1 - 0s - loss: 2.3989 - accuracy: 0.2857\n",
      "Epoch 25/250\n",
      "1/1 - 0s - loss: 2.3927 - accuracy: 0.2857\n",
      "Epoch 26/250\n",
      "1/1 - 0s - loss: 2.3862 - accuracy: 0.2857\n",
      "Epoch 27/250\n",
      "1/1 - 0s - loss: 2.3793 - accuracy: 0.2857\n",
      "Epoch 28/250\n",
      "1/1 - 0s - loss: 2.3720 - accuracy: 0.2857\n",
      "Epoch 29/250\n",
      "1/1 - 0s - loss: 2.3642 - accuracy: 0.2857\n",
      "Epoch 30/250\n",
      "1/1 - 0s - loss: 2.3559 - accuracy: 0.2857\n",
      "Epoch 31/250\n",
      "1/1 - 0s - loss: 2.3472 - accuracy: 0.2857\n",
      "Epoch 32/250\n",
      "1/1 - 0s - loss: 2.3379 - accuracy: 0.2857\n",
      "Epoch 33/250\n",
      "1/1 - 0s - loss: 2.3281 - accuracy: 0.2857\n",
      "Epoch 34/250\n",
      "1/1 - 0s - loss: 2.3176 - accuracy: 0.2857\n",
      "Epoch 35/250\n",
      "1/1 - 0s - loss: 2.3066 - accuracy: 0.2857\n",
      "Epoch 36/250\n",
      "1/1 - 0s - loss: 2.2948 - accuracy: 0.2857\n",
      "Epoch 37/250\n",
      "1/1 - 0s - loss: 2.2824 - accuracy: 0.2857\n",
      "Epoch 38/250\n",
      "1/1 - 0s - loss: 2.2693 - accuracy: 0.2857\n",
      "Epoch 39/250\n",
      "1/1 - 0s - loss: 2.2554 - accuracy: 0.2857\n",
      "Epoch 40/250\n",
      "1/1 - 0s - loss: 2.2408 - accuracy: 0.2857\n",
      "Epoch 41/250\n",
      "1/1 - 0s - loss: 2.2255 - accuracy: 0.2857\n",
      "Epoch 42/250\n",
      "1/1 - 0s - loss: 2.2095 - accuracy: 0.2857\n",
      "Epoch 43/250\n",
      "1/1 - 0s - loss: 2.1929 - accuracy: 0.2857\n",
      "Epoch 44/250\n",
      "1/1 - 0s - loss: 2.1757 - accuracy: 0.2857\n",
      "Epoch 45/250\n",
      "1/1 - 0s - loss: 2.1580 - accuracy: 0.2857\n",
      "Epoch 46/250\n",
      "1/1 - 0s - loss: 2.1401 - accuracy: 0.2857\n",
      "Epoch 47/250\n",
      "1/1 - 0s - loss: 2.1220 - accuracy: 0.2857\n",
      "Epoch 48/250\n",
      "1/1 - 0s - loss: 2.1042 - accuracy: 0.2857\n",
      "Epoch 49/250\n",
      "1/1 - 0s - loss: 2.0868 - accuracy: 0.2857\n",
      "Epoch 50/250\n",
      "1/1 - 0s - loss: 2.0703 - accuracy: 0.2857\n",
      "Epoch 51/250\n",
      "1/1 - 0s - loss: 2.0550 - accuracy: 0.2857\n",
      "Epoch 52/250\n",
      "1/1 - 0s - loss: 2.0415 - accuracy: 0.2857\n",
      "Epoch 53/250\n",
      "1/1 - 0s - loss: 2.0299 - accuracy: 0.2857\n",
      "Epoch 54/250\n",
      "1/1 - 0s - loss: 2.0207 - accuracy: 0.2857\n",
      "Epoch 55/250\n",
      "1/1 - 0s - loss: 2.0139 - accuracy: 0.2857\n",
      "Epoch 56/250\n",
      "1/1 - 0s - loss: 2.0093 - accuracy: 0.2857\n",
      "Epoch 57/250\n",
      "1/1 - 0s - loss: 2.0062 - accuracy: 0.2857\n",
      "Epoch 58/250\n",
      "1/1 - 0s - loss: 2.0039 - accuracy: 0.2857\n",
      "Epoch 59/250\n",
      "1/1 - 0s - loss: 2.0015 - accuracy: 0.2857\n",
      "Epoch 60/250\n",
      "1/1 - 0s - loss: 1.9985 - accuracy: 0.2857\n",
      "Epoch 61/250\n",
      "1/1 - 0s - loss: 1.9944 - accuracy: 0.2857\n",
      "Epoch 62/250\n",
      "1/1 - 0s - loss: 1.9893 - accuracy: 0.2857\n",
      "Epoch 63/250\n",
      "1/1 - 0s - loss: 1.9834 - accuracy: 0.2857\n",
      "Epoch 64/250\n",
      "1/1 - 0s - loss: 1.9769 - accuracy: 0.2857\n",
      "Epoch 65/250\n",
      "1/1 - 0s - loss: 1.9703 - accuracy: 0.2857\n",
      "Epoch 66/250\n",
      "1/1 - 0s - loss: 1.9638 - accuracy: 0.2857\n",
      "Epoch 67/250\n",
      "1/1 - 0s - loss: 1.9576 - accuracy: 0.2857\n",
      "Epoch 68/250\n",
      "1/1 - 0s - loss: 1.9519 - accuracy: 0.2857\n",
      "Epoch 69/250\n",
      "1/1 - 0s - loss: 1.9468 - accuracy: 0.2857\n",
      "Epoch 70/250\n",
      "1/1 - 0s - loss: 1.9421 - accuracy: 0.2857\n",
      "Epoch 71/250\n",
      "1/1 - 0s - loss: 1.9379 - accuracy: 0.2857\n",
      "Epoch 72/250\n",
      "1/1 - 0s - loss: 1.9340 - accuracy: 0.2857\n",
      "Epoch 73/250\n",
      "1/1 - 0s - loss: 1.9303 - accuracy: 0.2857\n",
      "Epoch 74/250\n",
      "1/1 - 0s - loss: 1.9268 - accuracy: 0.2857\n",
      "Epoch 75/250\n",
      "1/1 - 0s - loss: 1.9232 - accuracy: 0.2857\n",
      "Epoch 76/250\n",
      "1/1 - 0s - loss: 1.9197 - accuracy: 0.2857\n",
      "Epoch 77/250\n",
      "1/1 - 0s - loss: 1.9160 - accuracy: 0.2857\n",
      "Epoch 78/250\n",
      "1/1 - 0s - loss: 1.9122 - accuracy: 0.2857\n",
      "Epoch 79/250\n",
      "1/1 - 0s - loss: 1.9083 - accuracy: 0.2857\n",
      "Epoch 80/250\n",
      "1/1 - 0s - loss: 1.9044 - accuracy: 0.2857\n",
      "Epoch 81/250\n",
      "1/1 - 0s - loss: 1.9003 - accuracy: 0.2857\n",
      "Epoch 82/250\n",
      "1/1 - 0s - loss: 1.8962 - accuracy: 0.2857\n",
      "Epoch 83/250\n",
      "1/1 - 0s - loss: 1.8921 - accuracy: 0.2857\n",
      "Epoch 84/250\n",
      "1/1 - 0s - loss: 1.8880 - accuracy: 0.2857\n",
      "Epoch 85/250\n",
      "1/1 - 0s - loss: 1.8839 - accuracy: 0.2857\n",
      "Epoch 86/250\n",
      "1/1 - 0s - loss: 1.8799 - accuracy: 0.2857\n",
      "Epoch 87/250\n",
      "1/1 - 0s - loss: 1.8760 - accuracy: 0.2857\n",
      "Epoch 88/250\n",
      "1/1 - 0s - loss: 1.8721 - accuracy: 0.2857\n",
      "Epoch 89/250\n",
      "1/1 - 0s - loss: 1.8683 - accuracy: 0.2857\n",
      "Epoch 90/250\n",
      "1/1 - 0s - loss: 1.8645 - accuracy: 0.2857\n",
      "Epoch 91/250\n",
      "1/1 - 0s - loss: 1.8607 - accuracy: 0.2857\n",
      "Epoch 92/250\n",
      "1/1 - 0s - loss: 1.8569 - accuracy: 0.2857\n",
      "Epoch 93/250\n",
      "1/1 - 0s - loss: 1.8530 - accuracy: 0.2857\n",
      "Epoch 94/250\n",
      "1/1 - 0s - loss: 1.8491 - accuracy: 0.2857\n",
      "Epoch 95/250\n",
      "1/1 - 0s - loss: 1.8451 - accuracy: 0.2857\n",
      "Epoch 96/250\n",
      "1/1 - 0s - loss: 1.8410 - accuracy: 0.2857\n",
      "Epoch 97/250\n",
      "1/1 - 0s - loss: 1.8369 - accuracy: 0.2857\n",
      "Epoch 98/250\n",
      "1/1 - 0s - loss: 1.8327 - accuracy: 0.3214\n",
      "Epoch 99/250\n",
      "1/1 - 0s - loss: 1.8284 - accuracy: 0.3214\n",
      "Epoch 100/250\n",
      "1/1 - 0s - loss: 1.8240 - accuracy: 0.3214\n",
      "Epoch 101/250\n",
      "1/1 - 0s - loss: 1.8196 - accuracy: 0.3214\n",
      "Epoch 102/250\n",
      "1/1 - 0s - loss: 1.8150 - accuracy: 0.3214\n",
      "Epoch 103/250\n",
      "1/1 - 0s - loss: 1.8105 - accuracy: 0.3214\n",
      "Epoch 104/250\n",
      "1/1 - 0s - loss: 1.8058 - accuracy: 0.3214\n",
      "Epoch 105/250\n",
      "1/1 - 0s - loss: 1.8010 - accuracy: 0.3214\n",
      "Epoch 106/250\n",
      "1/1 - 0s - loss: 1.7962 - accuracy: 0.3214\n",
      "Epoch 107/250\n",
      "1/1 - 0s - loss: 1.7912 - accuracy: 0.3214\n",
      "Epoch 108/250\n",
      "1/1 - 0s - loss: 1.7861 - accuracy: 0.3571\n",
      "Epoch 109/250\n",
      "1/1 - 0s - loss: 1.7808 - accuracy: 0.3929\n",
      "Epoch 110/250\n",
      "1/1 - 0s - loss: 1.7754 - accuracy: 0.3929\n",
      "Epoch 111/250\n",
      "1/1 - 0s - loss: 1.7699 - accuracy: 0.3929\n",
      "Epoch 112/250\n",
      "1/1 - 0s - loss: 1.7643 - accuracy: 0.3929\n",
      "Epoch 113/250\n",
      "1/1 - 0s - loss: 1.7585 - accuracy: 0.3929\n",
      "Epoch 114/250\n",
      "1/1 - 0s - loss: 1.7525 - accuracy: 0.3929\n",
      "Epoch 115/250\n",
      "1/1 - 0s - loss: 1.7464 - accuracy: 0.3929\n",
      "Epoch 116/250\n",
      "1/1 - 0s - loss: 1.7402 - accuracy: 0.3929\n",
      "Epoch 117/250\n",
      "1/1 - 0s - loss: 1.7338 - accuracy: 0.3929\n",
      "Epoch 118/250\n",
      "1/1 - 0s - loss: 1.7272 - accuracy: 0.3929\n",
      "Epoch 119/250\n",
      "1/1 - 0s - loss: 1.7205 - accuracy: 0.3929\n",
      "Epoch 120/250\n",
      "1/1 - 0s - loss: 1.7136 - accuracy: 0.3929\n",
      "Epoch 121/250\n",
      "1/1 - 0s - loss: 1.7066 - accuracy: 0.3929\n",
      "Epoch 122/250\n",
      "1/1 - 0s - loss: 1.6994 - accuracy: 0.3929\n",
      "Epoch 123/250\n",
      "1/1 - 0s - loss: 1.6921 - accuracy: 0.3929\n",
      "Epoch 124/250\n",
      "1/1 - 0s - loss: 1.6846 - accuracy: 0.3929\n",
      "Epoch 125/250\n",
      "1/1 - 0s - loss: 1.6770 - accuracy: 0.3929\n",
      "Epoch 126/250\n",
      "1/1 - 0s - loss: 1.6692 - accuracy: 0.3929\n",
      "Epoch 127/250\n",
      "1/1 - 0s - loss: 1.6613 - accuracy: 0.4286\n",
      "Epoch 128/250\n",
      "1/1 - 0s - loss: 1.6532 - accuracy: 0.4286\n",
      "Epoch 129/250\n",
      "1/1 - 0s - loss: 1.6450 - accuracy: 0.4286\n",
      "Epoch 130/250\n",
      "1/1 - 0s - loss: 1.6367 - accuracy: 0.4286\n",
      "Epoch 131/250\n",
      "1/1 - 0s - loss: 1.6282 - accuracy: 0.4286\n",
      "Epoch 132/250\n",
      "1/1 - 0s - loss: 1.6197 - accuracy: 0.4286\n",
      "Epoch 133/250\n",
      "1/1 - 0s - loss: 1.6110 - accuracy: 0.4286\n",
      "Epoch 134/250\n",
      "1/1 - 0s - loss: 1.6022 - accuracy: 0.4286\n",
      "Epoch 135/250\n",
      "1/1 - 0s - loss: 1.5932 - accuracy: 0.4286\n",
      "Epoch 136/250\n",
      "1/1 - 0s - loss: 1.5842 - accuracy: 0.4286\n",
      "Epoch 137/250\n",
      "1/1 - 0s - loss: 1.5751 - accuracy: 0.4286\n",
      "Epoch 138/250\n",
      "1/1 - 0s - loss: 1.5659 - accuracy: 0.4286\n",
      "Epoch 139/250\n",
      "1/1 - 0s - loss: 1.5566 - accuracy: 0.4286\n",
      "Epoch 140/250\n",
      "1/1 - 0s - loss: 1.5472 - accuracy: 0.4643\n",
      "Epoch 141/250\n",
      "1/1 - 0s - loss: 1.5378 - accuracy: 0.5000\n",
      "Epoch 142/250\n",
      "1/1 - 0s - loss: 1.5282 - accuracy: 0.5000\n",
      "Epoch 143/250\n",
      "1/1 - 0s - loss: 1.5186 - accuracy: 0.5000\n",
      "Epoch 144/250\n",
      "1/1 - 0s - loss: 1.5089 - accuracy: 0.5000\n",
      "Epoch 145/250\n",
      "1/1 - 0s - loss: 1.4992 - accuracy: 0.5000\n",
      "Epoch 146/250\n",
      "1/1 - 0s - loss: 1.4894 - accuracy: 0.5357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "1/1 - 0s - loss: 1.4795 - accuracy: 0.5357\n",
      "Epoch 148/250\n",
      "1/1 - 0s - loss: 1.4696 - accuracy: 0.5357\n",
      "Epoch 149/250\n",
      "1/1 - 0s - loss: 1.4596 - accuracy: 0.5714\n",
      "Epoch 150/250\n",
      "1/1 - 0s - loss: 1.4495 - accuracy: 0.5714\n",
      "Epoch 151/250\n",
      "1/1 - 0s - loss: 1.4394 - accuracy: 0.5714\n",
      "Epoch 152/250\n",
      "1/1 - 0s - loss: 1.4293 - accuracy: 0.5714\n",
      "Epoch 153/250\n",
      "1/1 - 0s - loss: 1.4191 - accuracy: 0.5714\n",
      "Epoch 154/250\n",
      "1/1 - 0s - loss: 1.4089 - accuracy: 0.5714\n",
      "Epoch 155/250\n",
      "1/1 - 0s - loss: 1.3986 - accuracy: 0.5714\n",
      "Epoch 156/250\n",
      "1/1 - 0s - loss: 1.3883 - accuracy: 0.5714\n",
      "Epoch 157/250\n",
      "1/1 - 0s - loss: 1.3780 - accuracy: 0.5714\n",
      "Epoch 158/250\n",
      "1/1 - 0s - loss: 1.3677 - accuracy: 0.5714\n",
      "Epoch 159/250\n",
      "1/1 - 0s - loss: 1.3574 - accuracy: 0.5714\n",
      "Epoch 160/250\n",
      "1/1 - 0s - loss: 1.3470 - accuracy: 0.5714\n",
      "Epoch 161/250\n",
      "1/1 - 0s - loss: 1.3367 - accuracy: 0.5714\n",
      "Epoch 162/250\n",
      "1/1 - 0s - loss: 1.3264 - accuracy: 0.5714\n",
      "Epoch 163/250\n",
      "1/1 - 0s - loss: 1.3161 - accuracy: 0.5714\n",
      "Epoch 164/250\n",
      "1/1 - 0s - loss: 1.3058 - accuracy: 0.5714\n",
      "Epoch 165/250\n",
      "1/1 - 0s - loss: 1.2956 - accuracy: 0.5714\n",
      "Epoch 166/250\n",
      "1/1 - 0s - loss: 1.2855 - accuracy: 0.6071\n",
      "Epoch 167/250\n",
      "1/1 - 0s - loss: 1.2754 - accuracy: 0.6429\n",
      "Epoch 168/250\n",
      "1/1 - 0s - loss: 1.2653 - accuracy: 0.6429\n",
      "Epoch 169/250\n",
      "1/1 - 0s - loss: 1.2553 - accuracy: 0.6429\n",
      "Epoch 170/250\n",
      "1/1 - 0s - loss: 1.2454 - accuracy: 0.6429\n",
      "Epoch 171/250\n",
      "1/1 - 0s - loss: 1.2356 - accuracy: 0.6429\n",
      "Epoch 172/250\n",
      "1/1 - 0s - loss: 1.2259 - accuracy: 0.6429\n",
      "Epoch 173/250\n",
      "1/1 - 0s - loss: 1.2163 - accuracy: 0.6429\n",
      "Epoch 174/250\n",
      "1/1 - 0s - loss: 1.2067 - accuracy: 0.6429\n",
      "Epoch 175/250\n",
      "1/1 - 0s - loss: 1.1972 - accuracy: 0.6429\n",
      "Epoch 176/250\n",
      "1/1 - 0s - loss: 1.1879 - accuracy: 0.6429\n",
      "Epoch 177/250\n",
      "1/1 - 0s - loss: 1.1786 - accuracy: 0.6429\n",
      "Epoch 178/250\n",
      "1/1 - 0s - loss: 1.1695 - accuracy: 0.6429\n",
      "Epoch 179/250\n",
      "1/1 - 0s - loss: 1.1604 - accuracy: 0.6429\n",
      "Epoch 180/250\n",
      "1/1 - 0s - loss: 1.1514 - accuracy: 0.6429\n",
      "Epoch 181/250\n",
      "1/1 - 0s - loss: 1.1425 - accuracy: 0.6429\n",
      "Epoch 182/250\n",
      "1/1 - 0s - loss: 1.1337 - accuracy: 0.6429\n",
      "Epoch 183/250\n",
      "1/1 - 0s - loss: 1.1250 - accuracy: 0.6429\n",
      "Epoch 184/250\n",
      "1/1 - 0s - loss: 1.1164 - accuracy: 0.6429\n",
      "Epoch 185/250\n",
      "1/1 - 0s - loss: 1.1079 - accuracy: 0.6429\n",
      "Epoch 186/250\n",
      "1/1 - 0s - loss: 1.0995 - accuracy: 0.6429\n",
      "Epoch 187/250\n",
      "1/1 - 0s - loss: 1.0911 - accuracy: 0.6429\n",
      "Epoch 188/250\n",
      "1/1 - 0s - loss: 1.0828 - accuracy: 0.6429\n",
      "Epoch 189/250\n",
      "1/1 - 0s - loss: 1.0746 - accuracy: 0.6429\n",
      "Epoch 190/250\n",
      "1/1 - 0s - loss: 1.0665 - accuracy: 0.6429\n",
      "Epoch 191/250\n",
      "1/1 - 0s - loss: 1.0585 - accuracy: 0.6429\n",
      "Epoch 192/250\n",
      "1/1 - 0s - loss: 1.0505 - accuracy: 0.6429\n",
      "Epoch 193/250\n",
      "1/1 - 0s - loss: 1.0426 - accuracy: 0.6429\n",
      "Epoch 194/250\n",
      "1/1 - 0s - loss: 1.0348 - accuracy: 0.6429\n",
      "Epoch 195/250\n",
      "1/1 - 0s - loss: 1.0270 - accuracy: 0.6429\n",
      "Epoch 196/250\n",
      "1/1 - 0s - loss: 1.0193 - accuracy: 0.6429\n",
      "Epoch 197/250\n",
      "1/1 - 0s - loss: 1.0117 - accuracy: 0.6429\n",
      "Epoch 198/250\n",
      "1/1 - 0s - loss: 1.0041 - accuracy: 0.6429\n",
      "Epoch 199/250\n",
      "1/1 - 0s - loss: 0.9967 - accuracy: 0.6429\n",
      "Epoch 200/250\n",
      "1/1 - 0s - loss: 0.9892 - accuracy: 0.6429\n",
      "Epoch 201/250\n",
      "1/1 - 0s - loss: 0.9819 - accuracy: 0.6429\n",
      "Epoch 202/250\n",
      "1/1 - 0s - loss: 0.9746 - accuracy: 0.6429\n",
      "Epoch 203/250\n",
      "1/1 - 0s - loss: 0.9673 - accuracy: 0.6429\n",
      "Epoch 204/250\n",
      "1/1 - 0s - loss: 0.9601 - accuracy: 0.6429\n",
      "Epoch 205/250\n",
      "1/1 - 0s - loss: 0.9530 - accuracy: 0.6429\n",
      "Epoch 206/250\n",
      "1/1 - 0s - loss: 0.9460 - accuracy: 0.6429\n",
      "Epoch 207/250\n",
      "1/1 - 0s - loss: 0.9390 - accuracy: 0.6429\n",
      "Epoch 208/250\n",
      "1/1 - 0s - loss: 0.9320 - accuracy: 0.6429\n",
      "Epoch 209/250\n",
      "1/1 - 0s - loss: 0.9251 - accuracy: 0.6429\n",
      "Epoch 210/250\n",
      "1/1 - 0s - loss: 0.9183 - accuracy: 0.6429\n",
      "Epoch 211/250\n",
      "1/1 - 0s - loss: 0.9116 - accuracy: 0.6429\n",
      "Epoch 212/250\n",
      "1/1 - 0s - loss: 0.9048 - accuracy: 0.6429\n",
      "Epoch 213/250\n",
      "1/1 - 0s - loss: 0.8982 - accuracy: 0.6429\n",
      "Epoch 214/250\n",
      "1/1 - 0s - loss: 0.8916 - accuracy: 0.6786\n",
      "Epoch 215/250\n",
      "1/1 - 0s - loss: 0.8850 - accuracy: 0.7500\n",
      "Epoch 216/250\n",
      "1/1 - 0s - loss: 0.8785 - accuracy: 0.7500\n",
      "Epoch 217/250\n",
      "1/1 - 0s - loss: 0.8721 - accuracy: 0.7500\n",
      "Epoch 218/250\n",
      "1/1 - 0s - loss: 0.8657 - accuracy: 0.7500\n",
      "Epoch 219/250\n",
      "1/1 - 0s - loss: 0.8593 - accuracy: 0.7500\n",
      "Epoch 220/250\n",
      "1/1 - 0s - loss: 0.8530 - accuracy: 0.7500\n",
      "Epoch 221/250\n",
      "1/1 - 0s - loss: 0.8468 - accuracy: 0.7500\n",
      "Epoch 222/250\n",
      "1/1 - 0s - loss: 0.8406 - accuracy: 0.7500\n",
      "Epoch 223/250\n",
      "1/1 - 0s - loss: 0.8345 - accuracy: 0.7500\n",
      "Epoch 224/250\n",
      "1/1 - 0s - loss: 0.8284 - accuracy: 0.7500\n",
      "Epoch 225/250\n",
      "1/1 - 0s - loss: 0.8223 - accuracy: 0.7500\n",
      "Epoch 226/250\n",
      "1/1 - 0s - loss: 0.8163 - accuracy: 0.7500\n",
      "Epoch 227/250\n",
      "1/1 - 0s - loss: 0.8103 - accuracy: 0.7857\n",
      "Epoch 228/250\n",
      "1/1 - 0s - loss: 0.8044 - accuracy: 0.8214\n",
      "Epoch 229/250\n",
      "1/1 - 0s - loss: 0.7985 - accuracy: 0.8214\n",
      "Epoch 230/250\n",
      "1/1 - 0s - loss: 0.7927 - accuracy: 0.8214\n",
      "Epoch 231/250\n",
      "1/1 - 0s - loss: 0.7869 - accuracy: 0.8214\n",
      "Epoch 232/250\n",
      "1/1 - 0s - loss: 0.7812 - accuracy: 0.8214\n",
      "Epoch 233/250\n",
      "1/1 - 0s - loss: 0.7755 - accuracy: 0.8214\n",
      "Epoch 234/250\n",
      "1/1 - 0s - loss: 0.7698 - accuracy: 0.8214\n",
      "Epoch 235/250\n",
      "1/1 - 0s - loss: 0.7642 - accuracy: 0.8214\n",
      "Epoch 236/250\n",
      "1/1 - 0s - loss: 0.7586 - accuracy: 0.8214\n",
      "Epoch 237/250\n",
      "1/1 - 0s - loss: 0.7531 - accuracy: 0.8214\n",
      "Epoch 238/250\n",
      "1/1 - 0s - loss: 0.7476 - accuracy: 0.8214\n",
      "Epoch 239/250\n",
      "1/1 - 0s - loss: 0.7421 - accuracy: 0.8214\n",
      "Epoch 240/250\n",
      "1/1 - 0s - loss: 0.7367 - accuracy: 0.8214\n",
      "Epoch 241/250\n",
      "1/1 - 0s - loss: 0.7314 - accuracy: 0.8214\n",
      "Epoch 242/250\n",
      "1/1 - 0s - loss: 0.7260 - accuracy: 0.8214\n",
      "Epoch 243/250\n",
      "1/1 - 0s - loss: 0.7207 - accuracy: 0.8214\n",
      "Epoch 244/250\n",
      "1/1 - 0s - loss: 0.7155 - accuracy: 0.8214\n",
      "Epoch 245/250\n",
      "1/1 - 0s - loss: 0.7103 - accuracy: 0.8214\n",
      "Epoch 246/250\n",
      "1/1 - 0s - loss: 0.7051 - accuracy: 0.8214\n",
      "Epoch 247/250\n",
      "1/1 - 0s - loss: 0.6999 - accuracy: 0.8214\n",
      "Epoch 248/250\n",
      "1/1 - 0s - loss: 0.6948 - accuracy: 0.8214\n",
      "Epoch 249/250\n",
      "1/1 - 0s - loss: 0.6898 - accuracy: 0.8214\n",
      "Epoch 250/250\n",
      "1/1 - 0s - loss: 0.6847 - accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "#모델 생성\n",
    "model = Sequential()\n",
    "#희소행렬로 변환 (10:벡터)\n",
    "model.add(Embedding(vocab_size, 10, input_length=X.shape[1]))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "#모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 학습시키기\n",
    "hist = model.fit(X, Y, epochs=250, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
