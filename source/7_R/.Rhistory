geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=1)
#노년층(수) 많은 지역순
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=0)
#노년층(수) 많은 지역순
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=1.1)
#노년층(수) 많은 지역순
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=1.1) +
theme(legend.position = "none")
#노년층(수) 많은 지역순
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=1.1) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col()
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col()
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(strinr:str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), njust=-0.5)
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr:str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), njust=-0.5)
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr:str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.5)
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.5)
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.5) +
theme(legend.position = "none")
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.5) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=0) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=reorder(region, n), y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
#노년층(수) 많은 지역순
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_label(aes(label=n), fill="white", nudge_y=1.1) + #막대 그래프에 y축 라벨 적기(1)
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=reorder(region, n), y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=reorder(region, n), y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=reorder(region, n), y=n, fill=region)) +
geom_col()
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=reorder(region, n), y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10)) +
aes(x=reorder(region, n))
temp %>%
filter(agegrade=='old') %>%
arrange(-n) %>%
ggplot(aes(x=region, y=n, fill=region)) +
geom_col() +
aes(stringr::str_wrap(region, 6), n) +
labs(x="지역", y="노년층 인구") +
geom_text(aes(label=n), vjust=-0.2) +
theme(legend.position = "none") +
scale_fill_manual(values=topo.colors(10))
rm(list=ls())
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
#R에서 우측 하단의 Packages -> install 도구를 이용해서 설치(수동 설치)시 필요한 패키지 설치
install.packages("devtools")
#KoNLP가 의존하는 패키지 설치
install.packages("hash")
install.packages("tau")
install.packages("Sejong")
install.packages("C:/Bigdata_자료(git에 올리지 않는 자료들)/DOWNLOAD/KoNLP_0.80.2.tar.gz", repos = NULL, type = "source")
library(KoNLP)
Sys.getenv("JAVA_HOME")
#사전 설정하기
useNIADic()
extractNoun('대한민국의 영토는 한반도와 그 부속 도서로 한다')
extractNoun('의미있는 하루 하루, 항상 감사한 하루가 되길')
#1. 힙합 가사 텍스트 마이닝
txt <-readLines('inData/hiphop.txt')
txt
head(txt)
#gsub(oldStr, newStrn string)
#str_replace_all(string, oldStr, newStr)
library(stringr)
temp <-gsub('\\W', ' ', txt)
txt <-str_replace_all(txt, '\\W', ' ')
table(temp==txt)
# 1.3 명사 추출
head(txt)
nouns <-extractNoun(txt)
class(nouns)
head(unlist(nouns))
table(unlist(nouns))
wordcount <-table(unlist(nouns))
class(wordcount)
sort(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors = F)
#stringsAsFactors=F; 문자를 chr 타입으로 하기 위함(factor 타입X)
head(df_word, 10)
str(df_word, 10)
str(df_word)
library(dplyr)
df_word <-rename(df_word, word=Var1, freq=Freq)
str(df_word)
head(df_word)
nrow(df_word)
df_word %>%
filter(nchar(word)>=2)
df_word <-filter(df_word, nchar(word)>=2)
head(df_word)
#자주 사용되는 단어 빈도표 top20 만들기
top20 <-df_word[order(-df_word$freq), ][1:20]
#자주 사용되는 단어 빈도표 top20 만들기
top20 <-df_word[order(-df_word$freq), ][1:20,]
top20
top20 <-df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
#자주 사용되는 단어 top20 그래프 그리기
library(ggplot2)
ggplot(data=top20, aes(x=freq, y=reorder(word, freq))) +
geom_col()
ggplot(data=top20, aes(x=freq, y=reorder(word, freq))) +
geom_col() +
geom_text(aes(label=freq), hjust=1.2, col="white") +
labs(title="자주 사용되는 단어 top20",
x="출현 빈도", y="출현 단어")
ggplot(data=top20, aes(x=freq, y=reorder(word, freq))) +
geom_col() +
geom_text(aes(label=freq), hjust=1.2, col="white") +
labs(title="자주 사용되는 단어 top20",
subtitle="(힙합가사)"
x="출현 빈도", y="출현 단어")
ggplot(data=top20, aes(x=freq, y=reorder(word, freq))) +
geom_col() +
geom_text(aes(label=freq), hjust=1.2, col="white") +
labs(title="자주 사용되는 단어 top20",
subtitle="(힙합가사)",
x="출현 빈도", y="출현 단어")
ggplot(data=top20, aes(x=freq, y=reorder(word, freq))) +
geom_col() +
geom_text(aes(label=freq), hjust=1.2, col="white") +
labs(title="힙합 가사에 자주 사용되는 단어 top20",
x="출현 빈도", y="출현 단어")
install.packages("wordcloud")
library(wordcloud)
round(runif(6, min=1, max=45))
display.brewer.all()
?wordcloud
pal <-brewer.pal(8, "Dark2")
set.seed(1234)
wordcloud(word=df_word$word, #출력될 단어
freq=df_word$freq, #단어 빈도
min.freq=2,        #최소 단어 빈도
max.words=200,     #표현 단어 수
random.order = F,  #고빈도 단어 중앙 배치
rot.per=.1,        #회전 단어 비율
scale=c(2,0.3),    #단어 크기 범위
colors=pal)        #색깔 목록 지정
wordcloud(words=df_word$word,
freq=df_word$freq,
min.freq = 2,
max.words=200,
random.order = F,
ort.per=.1,
scale=c(2,0.3),
colors=rainbow(16)) #pal대신 rainbow, topo.colors 등 사용 가능
wordcloud(words=df_word$word,
freq=df_word$freq,
min.freq = 2,
max.words=200,
random.order = F,
ort.per=.1,
scale=c(2,0.3),
colors=pal) #pal대신 rainbow, topo.colors 등 사용 가능
# 2. 국정원 트윗 데이터 텍스트 마이닝
twitter <-read.csv("inData/twitter.csv",
header=T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
head(twitter)
View(twitter)
nouns <-extractNoun(twitter$tw)
head(nouns)
class(nouns)
wordcount <-table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors = FALSE)
df_word <-rename(df_word, word=Var1, freq=Freq)
head(df_word)
wordcount <-table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors = FALSE)
head(df_word)
nouns <- extractNoun(twitter$tw)
head(nouns)
class(nouns)
wordcount <- table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors=FALSE)
df_word <-rename(df_word, word=Var1, freq=Freq)
str(df_word)
head(df_word)
# 2. 국정원 트윗 데이터 텍스트 마이닝
twitter <-read.csv("inData/twitter.csv",
header=T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
head(twitter)
nouns <- extractNoun(twitter$tw)
head(nouns)
class(nouns)
wordcount <- table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors=FALSE)
df_word <-rename(df_word, word=Var1, freq=Freq)
head(nouns)
df_word <-as.data.frame(wordcount, stringsAsFactors=FALSE)
head(df_word)
# 2. 국정원 트윗 데이터 텍스트 마이닝
twitter <-read.csv("inData/twitter.csv",
header=T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
head(twitter)
View(twitter)
nouns <- extractNoun(twitter$tw)
head(nouns)
class(nouns)
wordcount <- table(unlist(nouns))
nouns
nouns <- extractNoun(twitter$tw)
nouns <- extractNoun(twitter$tw)
# 2. 국정원 트윗 데이터 텍스트 마이닝
twitter <-read.csv("inData/twitter.csv",
header=T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
head(twitter)
View(twitter)
nouns <- extractNoun(twitter$tw)
# 2. 국정원 트윗 데이터 텍스트 마이닝
twitter <-read.csv("inData/twitter.csv",
header=T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
head(twitter)
class(twitter)
twitter <-rename(twitter,
no=번호,
id=계정이름,
date=작성일,
tw=내용)
edit(twitter)
#필요 없는 문자, 단어 삭제하기
twitter$tw <-str_replace_all(twitter$tw, '\\W', ' ')
twitter$tw <-str_replace_all(twitter$tw, '[ㄱ-ㅎ]', ' ')
twitter$tw <-str_replace_all(twitter$tw, '  ', ' ')
twitter$tw <-str_replace_all(twitter$tw, '  ', ' ') #스페이스 줄이기기
head(twitter)
nouns <-extractNoun(twitter$tw)
head(nouns)
class(nouns)
wordcount <-table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors = F)
df_word <-rename(df_word, word=Var1, freq=Freq)
str(df_word)
head(df_word)
#출현단어 중 2글자 이상만 분석
df_word <-filter(df_word, nchar(word)>1)
#최빈 단어 top20 출력, 그래프
top 20 <-df_word[order(df_word$freq, decreasing = T), ][1:20, ]
top20
#최빈 단어 top20 출력, 그래프
top20 <-df_word[order(df_word$freq, decreasing = T), ][1:20, ]
top20
#최빈 단어 top20 출력, 그래프
top20 <-df_word[order(df_word$freq, decreasing = T), ][1:20, ]
top20
df_word %>%
arrange(desc(freq)) %>%
head(20) %>%
ggplot(aes(x=freq, y=reorder(word, freq))) +
geom_bar(stat="identity")
df_word %>%
arrange(desc(freq)) %>%
head(20) %>%
ggplot(aes(x=freq, y=reorder(word, freq))) +
geom_bar(stat="identity") +
labs(x="출현 빈도", y="출현 단어")
df_word %>%
arrange(desc(freq)) %>%
head(20) %>%
ggplot(aes(x=freq, y=reorder(word, freq))) +
geom_bar(stat="identity") +
labs(x="빈도", y="출현 단어")
ggplot(top20, aes(x=freq, y=reorder(word, freq))) +
geom_col() +
labs(x="출현 빈도", y="출현 단어") +
geom_text(aes(label=freq), hjust=1.2, col="white")
#워드클라우드 그리기
set.seed(1234)
pal <-brewer.pal(9, "Blues")[5:9]
wordcloud(word=df_word$word,
freq=df_word$freq,
min.freq = 5,
max.words = 300,
random.order = F,
rot.per=0.1,
scale=c(3, 0.3),
colors=pal)
sort(table(twitter$id))
more150Id <-twitter %>%
group_by(id) %>%
summarise(n=n()) %>%
filter(n>150)
more150 <- twitter %>%
filter(id %in% more150Id$id) %>%
select(id, tw)
table(more150$id)
more150$tw <-str_replace_all(more150$tw, '\\W', ' ')
more150$tw <-str_replace_all(more150$tw, '[ㄱ-ㅎ]', ' ')
more150$tw <-str_replace_all(more150$tw, '  ', ' ')
nouns <-extractNoun(more150$tw)
head(nouns)
class(nouns)
wordcount <-table(unlist(nouns))
class(wordcount)
df_word <-as.data.frame(wordcount, stringsAsFactors = F)
head(df_word)
df_word <-rename(df_word, word=Var1, freq=Freq)
str(df_word)
df_word <-filter(df_word, nchar(word)>1)
wordcloud(word=df_word$word,
freq=df_word$freq,
min.freq = 5,
max.words = 200,
random.order = F,
rot.per=0.1,
sclae=c(3, 0.3),
color=pal)
wordcloud(word=df_word$word,
freq=df_word$freq,
min.freq = 5,
max.words = 300,
random.order = F,
rot.per=0.1,
sclae=c(3, 0.3),
color=pal)
df_word %>%
arrange(-freq) %>%
head(20)
df_word %>%
arrange(-freq) %>%
head(20) %>%
ggplot(aes(x=freq, y=reorder(word, freq))) +
geom_col() +
geom_text(aes(label=freq), col="yellow", hjust=1.1) +
labs(y="단어", x="출현 빈도 수",
title="150회 이상 트윗한 아이디 게시물의 최빈 단어")
set.seed(1234)
wordcloud(word=df_word$word,
freq=df_word$freq,
min.freq = 5,
max.words = 300,
random.order = F,
rot.per=0.1,
sclae=c(3, 0.3),
color=pal)
